# encoding:utf-8import requestsimport urllibimport refrom bs4 import BeautifulSoupa=input("how many latest papers do you want to download : ")print(a)page = requests.get('https://arxiv.org/list/cs.CR/recent').text# print(page.status)soup=BeautifulSoup(page,'lxml')div_list=soup.find_all('div',attrs={'class':'meta'})num=1for tag_div in div_list:    tag_name=tag_div.select('div.list-title.mathjax')    if tag_name:        if num>int(a):            break        filename=tag_name[0].get_text().strip().replace('Title: ','').replace(':','_').replace(' ','_')+'.pdf'        print('下载文件%d：'%num,filename)        tag_dt=tag_div.parent.previous_sibling.previous_sibling        tag_a=tag_dt.find('a',attrs={'href':re.compile('(/pdf/.+?)')})        pdf_url='https://arxiv.org'+tag_a.attrs['href']+'.pdf'        urllib.request.urlretrieve(pdf_url, filename)                #r = requests.get(pdf_url)         #with open(filename, "wb") as f:            #f.write(r.content)        print(filename,'下载结束')        num+=1                                 #print htmlcode# reg = r'<a href="(/pdf/.+?)" title'# reg_pdf = re.compile(reg)# pdf_list_all = reg_pdf.findall(htmlcode)# pdf_list = []# n=0# for i in range(a) :#     pdf_list.append(pdf_list_all[n])#     n += 1# n=0# pdf_name = []# for i in pdf_list:#     pdf_name_tmp=pdf_list[n]#     pdf_name_tmp=pdf_name_tmp.replace(".","_")#     pdf_name_tmp=pdf_name_tmp.replace("/pdf/","")#     pdf_name.append(pdf_name_tmp)#     n += 1# x=0# for pdf in pdf_list[0:a]:#     pdf_url = 'https://arxiv.org' + pdf + '.pdf'#     print ('downloading %s \n' %pdf_name[x])#     urllib.urlretrieve(pdf_url, '%s.pdf' %pdf_name[x])#     print ('finish downloading NO.%d\n\n'%(x+1))#     x += 1